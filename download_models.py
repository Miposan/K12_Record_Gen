#!/usr/bin/env python3
"""
é€šç”¨Hugging Faceæ¨¡å‹ä¸‹è½½è„šæœ¬
æ”¯æŒé•œåƒç«™ä¸‹è½½ï¼Œæ–­ç‚¹ç»­ä¼ ï¼Œå¤šçº¿ç¨‹åŠ é€Ÿ
"""

import os
import sys
import requests
import json
from pathlib import Path
from typing import List, Dict, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp
import time
from tqdm import tqdm
import argparse

class HFModelDownloader:
    def __init__(self, mirror: str = "hf-mirror.com"):
        self.mirror = mirror
        self.base_url = f"https://{mirror}"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
    def get_model_info(self, model_id: str) -> Dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        api_url = f"{self.base_url}/api/models/{model_id}"
        try:
            response = self.session.get(api_url, timeout=30)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def get_model_files(self, model_id: str) -> List[Dict]:
        """è·å–æ¨¡å‹æ–‡ä»¶åˆ—è¡¨"""
        api_url = f"{self.base_url}/api/models/{model_id}/tree/main"
        try:
            response = self.session.get(api_url, timeout=30)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def download_file(self, model_id: str, filename: str, local_dir: str, 
                     chunk_size: int = 8*1024*1024, max_retries: int = 3) -> bool:
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        # ä¸ºæ¯ä¸ªè¿›ç¨‹åˆ›å»ºç‹¬ç«‹çš„sessionå¯¹è±¡
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        local_path = Path(local_dir) / filename
        local_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ„å»ºä¸‹è½½URL
        url = f"{self.base_url}/{model_id}/resolve/main/{filename}"
        
        # æ™ºèƒ½æ–­ç‚¹ç»­ä¼ æ£€æŸ¥
        resume_pos = 0
        use_resume = False
        
        if local_path.exists():
            file_size = local_path.stat().st_size
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼ˆé€šè¿‡HEADè¯·æ±‚è·å–è¿œç¨‹æ–‡ä»¶å¤§å°ï¼‰
            try:
                head_response = session.head(url, timeout=10)
                remote_size = int(head_response.headers.get('content-length', 0))
                
                if file_size >= remote_size:
                    # æ–‡ä»¶å·²å®Œæ•´ä¸‹è½½
                    print(f"âœ… {filename} å·²å­˜åœ¨ä¸”å®Œæ•´ï¼Œè·³è¿‡ä¸‹è½½")
                    return True
                elif file_size > 1024 * 1024:  # åªå¯¹å¤§æ–‡ä»¶ä½¿ç”¨æ–­ç‚¹ç»­ä¼ 
                    resume_pos = file_size
                    use_resume = True
                    print(f"ğŸ”„ {filename} æ–­ç‚¹ç»­ä¼ : {file_size}/{remote_size} bytes")
            except Exception as e:
                # HEADè¯·æ±‚å¤±è´¥ï¼Œåˆ é™¤æ–‡ä»¶é‡æ–°ä¸‹è½½
                print(f"âš ï¸ {filename} HEADè¯·æ±‚å¤±è´¥: {e}ï¼Œé‡æ–°ä¸‹è½½")
                try:
                    local_path.unlink()
                except:
                    pass
        
        headers = {}
        if use_resume and resume_pos > 0:
            headers['Range'] = f'bytes={resume_pos}-'
        
        for attempt in range(max_retries):
            try:
                response = session.get(url, headers=headers, stream=True, timeout=60)
                response.raise_for_status()
                
                # å¤„ç†æ–­ç‚¹ç»­ä¼ 
                
                total_size = int(response.headers.get('content-length', 0)) + resume_pos
                
                with open(local_path, 'ab' if resume_pos > 0 else 'wb') as f:
                    # ç®€åŒ–è¿›åº¦æ˜¾ç¤ºï¼Œåªæ˜¾ç¤ºæ–‡ä»¶åå’Œå¤§å°
                    desc = f"{filename[:30]}..." if len(filename) > 30 else filename
                    with tqdm(total=total_size, initial=resume_pos, unit='B', 
                             unit_scale=True, desc=desc, leave=False, 
                             bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:
                        for chunk in response.iter_content(chunk_size=chunk_size):
                            if chunk:
                                f.write(chunk)
                                pbar.update(len(chunk))
                
                print(f"âœ… {filename} ä¸‹è½½å®Œæˆ")
                return True
                
            except Exception as e:
                print(f"âŒ {filename} ä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œåˆ é™¤å¯èƒ½æŸåçš„æ–‡ä»¶
                    try:
                        local_path.unlink()
                    except:
                        pass
        
        # å…³é—­session
        session.close()
        return False
    
    def download_model(self, model_id: str, local_dir: str = None, 
                      max_workers: int = 4, include_patterns: List[str] = None,
                      exclude_patterns: List[str] = None) -> bool:
        """ä¸‹è½½æ•´ä¸ªæ¨¡å‹"""
        # æå–æ¨¡å‹åç§°ï¼ˆå»æ‰ç»„ç»‡åï¼‰
        model_name = model_id.split('/')[-1]
        
        if local_dir is None:
            local_dir = f"./models/{model_name}"
        else:
            # å¦‚æœæŒ‡å®šäº†local_dirï¼Œåœ¨ä¸‹é¢åˆ›å»ºæ¨¡å‹åç§°å­ç›®å½•
            local_dir = f"{local_dir}/{model_name}"
        
        local_path = Path(local_dir)
        local_path.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸš€ å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_id}")
        print(f"ğŸ“ ä¿å­˜åˆ°: {local_path.absolute()}")
        
        # è·å–æ–‡ä»¶åˆ—è¡¨
        files = self.get_model_files(model_id)
        if not files:
            print("âŒ æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨")
            return False
        
        # è¿‡æ»¤æ–‡ä»¶
        download_files = []
        for file_info in files:
            filename = file_info.get('path', '')
            if not filename or file_info.get('type') == 'directory':
                continue
                
            # åº”ç”¨åŒ…å«/æ’é™¤æ¨¡å¼
            if include_patterns and not any(pattern in filename for pattern in include_patterns):
                continue
            if exclude_patterns and any(pattern in filename for pattern in exclude_patterns):
                continue
            
            download_files.append(filename)
        
        print(f"ğŸ“„ éœ€è¦ä¸‹è½½ {len(download_files)} ä¸ªæ–‡ä»¶")
        
        # å¤šè¿›ç¨‹ä¸‹è½½
        # é™åˆ¶æœ€å¤§è¿›ç¨‹æ•°ï¼Œé¿å…åˆ›å»ºè¿‡å¤šè¿›ç¨‹
        actual_workers = min(max_workers, len(download_files), mp.cpu_count())
        print(f"ğŸ”„ ä½¿ç”¨ {actual_workers} ä¸ªè¿›ç¨‹å¹¶è¡Œä¸‹è½½")
        
        # åˆ›å»ºè¿›åº¦è·Ÿè¸ª
        completed_files = []
        failed_files = []
        
        with ProcessPoolExecutor(max_workers=actual_workers) as executor:
            future_to_file = {
                executor.submit(self.download_file, model_id, filename, str(local_path)): filename
                for filename in download_files
            }
            
            # ä½¿ç”¨æ›´æ¸…æ™°çš„è¿›åº¦æ˜¾ç¤º
            with tqdm(total=len(download_files), desc="æ€»ä½“è¿›åº¦", unit="æ–‡ä»¶") as pbar:
                for future in as_completed(future_to_file, timeout=3600):  # 1å°æ—¶è¶…æ—¶
                    filename = future_to_file[future]
                    try:
                        result = future.result(timeout=300)  # 5åˆ†é’Ÿå•ä¸ªæ–‡ä»¶è¶…æ—¶
                        if result:
                            completed_files.append(filename)
                            pbar.set_postfix({"æˆåŠŸ": len(completed_files), "å¤±è´¥": len(failed_files)})
                        else:
                            failed_files.append(filename)
                            pbar.set_postfix({"æˆåŠŸ": len(completed_files), "å¤±è´¥": len(failed_files)})
                        pbar.update(1)
                    except Exception as e:
                        failed_files.append(filename)
                        print(f"\nâŒ {filename} ä¸‹è½½å¼‚å¸¸: {e}")
                        pbar.set_postfix({"æˆåŠŸ": len(completed_files), "å¤±è´¥": len(failed_files)})
                        pbar.update(1)
        
        success_count = len(completed_files)
        print(f"ğŸ‰ ä¸‹è½½å®Œæˆ! æˆåŠŸ: {success_count}/{len(download_files)}")
        
        # å¦‚æœæœ‰å¤±è´¥çš„æ–‡ä»¶ï¼Œæ˜¾ç¤ºå®ƒä»¬
        if failed_files:
            print(f"âŒ ä»¥ä¸‹æ–‡ä»¶ä¸‹è½½å¤±è´¥:")
            for filename in failed_files:
                print(f"   - {filename}")
        
        return success_count == len(download_files)

def main():
    parser = argparse.ArgumentParser(description="é€šç”¨Hugging Faceæ¨¡å‹ä¸‹è½½è„šæœ¬")
    parser.add_argument("--model_id", help="æ¨¡å‹IDï¼Œå¦‚: Qwen/Qwen2.5-VL-7B-Instruct")
    parser.add_argument("--local-dir", help="æœ¬åœ°ä¿å­˜ç›®å½•")
    parser.add_argument("--mirror", default="hf-mirror.com", help="é•œåƒç«™ç‚¹")
    parser.add_argument("--max-workers", type=int, default=4, help="æœ€å¤§å¹¶å‘æ•°")
    parser.add_argument("--include", nargs="*", help="åŒ…å«çš„æ–‡ä»¶æ¨¡å¼")
    parser.add_argument("--exclude", nargs="*", help="æ’é™¤çš„æ–‡ä»¶æ¨¡å¼")
    
    args = parser.parse_args()
    
    downloader = HFModelDownloader(mirror=args.mirror)
    
    model_id = args.model_id
    
    success = downloader.download_model(
        model_id=model_id,
        local_dir=args.local_dir,
        max_workers=args.max_workers,
        include_patterns=args.include,
        exclude_patterns=args.exclude
    )
    
    if success:
        print("ğŸ‰ æ¨¡å‹ä¸‹è½½æˆåŠŸ!")
    else:
        print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥!")
        sys.exit(1)

if __name__ == "__main__":
    main()

# python download_models.py --model_id Qwen/Qwen2.5-VL-7B-Instruct --local-dir /home/cike/pre-trained --max-workers 4

# python download_models.py --model_id OpenGVLab/InternVL3_5-8B --local-dir /home/cike/pre-trained --max-workers 4


# python download_models.py --model_id lmms-lab/LLaVA-OneVision-1.5-8B-Instruct --local-dir /home/cike/pre-trained --max-workers 3